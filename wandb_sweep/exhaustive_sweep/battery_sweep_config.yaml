program: ../../trainer.py
project: gridrl
method: grid
parameters:
  env:
    domain_randomization:
      noise_std:
        value: 0.01
    observation_keys:
      values:
        - ['soc', 'net_load', 'import_price_current']
        - ['soc', 'net_load', 'import_price_current', 'import_price_forecast_0', 'import_price_forecast_1', 'import_price_forecast_2', 'import_price_forecast_3', 'import_price_forecast_4', 'import_price_forecast_5']
#        - ['soc', 'net_load', 'import_price_current', 'import_price_forecast_0', 'import_price_forecast_1', 'import_price_forecast_2', 'import_price_forecast_3', 'import_price_forecast_4', 'import_price_forecast_5',  'import_price_forecast_6', 'import_price_forecast_7', 'import_price_forecast_8', 'import_price_forecast_9', 'import_price_forecast_10', 'import_price_forecast_11', 'import_price_forecast_12', 'import_price_forecast_13', 'import_price_forecast_14', 'import_price_forecast_15', 'import_price_forecast_16', 'import_price_forecast_17',  'import_price_forecast_18', 'import_price_forecast_19', 'import_price_forecast_20', 'import_price_forecast_21', 'import_price_forecast_22']
  context:
    seed:
      value: 42
  algo:
    train:
      n_epochs:
        value: 100
    sampler:
      n_workers:
        value: 16
    policy:
      hidden_sizes:
        value: [128, 128]
    ppo:
      tanhnormal:
        value: false
    rnd:
      predictor_lr:
        value: 1.0e-3
      intrinsic_reward_weight:
        value: 0.1
  microgrid:
    methods:
      set_forecaster:
        forecast_horizon:
          value: 23
        forecaster:
          value: 0
        forecaster_increase_uncertainty:
          value: false
        forecaster_relative_noise:
          value: false
      set_module_attrs:
        battery_transition_model:
          values:
            - '!DecayCycleTransitionModel {decay_rate_per_cycle: 0.99975}'
            - '!DecayCycleTransitionModel {decay_rate_per_cycle: 0.99952}'
            - '!DecayTransitionModel {decay_rate: 0.999958}'
metric:
  name: Test/MPCRelativeRewardSum
  goal: minimize
  target: 0.8
command:
  - ${envvar:CONDA_PREFIX}/bin/python
  - ${program}
  - "--config"
  - ${envvar:BASED_ON_CONFIG}
  - ${args}
meta:
  agent_timeout: 3600
  agent_count: 10
  config_from_run: null
  wandb_setup:
    api_key_file: ../../local/wandb_api_key.txt
    username: ahalev
  sweep_id: null
  launch_agent: false
  scenario: null  # read from config_from_run